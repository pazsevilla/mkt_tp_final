# ğŸ’¡ TP Final â€“ Ecosistema de Datos Comercial (Data Warehouse + STAR Schema)

Trabajo PrÃ¡ctico Final de la materia **IntroducciÃ³n al Marketing Online y los Negocios Digitales** â€“ Universidad Austral (2025).

---

## ğŸ¯ Objetivo del Trabajo

DiseÃ±ar e implementar un **miniâ€“ecosistema de datos comercial (online + offline)** para la empresa ficticia *EcoBottle*, construir un **pipeline ETL** en Python y generar un **Data Warehouse dimensional (STAR SCHEMA)** listo para anÃ¡lisis y visualizaciÃ³n de KPIs clave del negocio:

- Ventas totales  
- Usuarios activos  
- Ticket promedio  
- Ventas por provincia  
- Ranking mensual por producto  
- NPS

Las fuentes de datos provienen de 13 archivos `.csv` con informaciÃ³n de clientes, pedidos, productos, pagos, envÃ­os, sesiones web y respuestas NPS.

Este repositorio contiene el cÃ³digo necesario para transformar los datos crudos en un Data Warehouse, exportado como CSV dentro de `warehouse/`, listo para su uso en herramientas BI como **Looker Studio o Power BI**.

---

## ğŸ§± Arquitectura del Proyecto
```mkt_tp_final/
â”‚
â”œâ”€â”€ raw/ # Datos transaccionales crudos (.csv)
â”‚
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ extract/ # Lectura de fuentes raw
â”‚ â”œâ”€â”€ transform/ # Limpieza + surrogate keys + joins
â”‚ â”œâ”€â”€ load/ # ExportaciÃ³n al Data Warehouse
â”‚
â”œâ”€â”€ warehouse/ # âœ… Data Warehouse final
â”‚ â”œâ”€â”€ dim/ # Dimensiones transformadas
â”‚ â””â”€â”€ fact/ # Tablas de hechos transformadas
â”‚
â””â”€â”€ main.py # Orquestador del pipeline ETL
```

---

## âš™ï¸ DescripciÃ³n del Pipeline ETL

### âœ… 1) Extract
Lectura automÃ¡tica de los 13 archivos CSV desde `/raw/` usando Pandas.

### âœ… 2) Transform
- Limpieza de datos y estandarizaciÃ³n  
- ConversiÃ³n de fechas y tipos
- GeneraciÃ³n de **surrogate keys (PK artificiales)**
- Reemplazo de IDs naturales por SK (en hechos)
- DesnormalizaciÃ³n para STAR SCHEMA
- ConstrucciÃ³n de dimensiones y hechos

### âœ… 3) Load
Exporta los resultados a:
warehouse/
â”œâ”€â”€ dim/
â””â”€â”€ fact/

Cada archivo CSV generado estÃ¡ listo para ser usado en una herramienta BI.

---

## ğŸŒŸ Modelo Estrella (STAR SCHEMA)

### ğŸ“Œ Dimensiones generadas

| Tabla | Contenido | Primary Key |
|-------|-----------|-------------|
| `dim_date` | calendario (dÃ­a, mes, aÃ±o, trimestre, nombre del dÃ­a) | `date_sk` |
| `dim_customer` | datos de clientes | `customer_sk` |
| `dim_product` | producto + categorÃ­a desnormalizada | `product_sk` |
| `dim_channel` | canales de venta | `channel_sk` |
| `dim_address` | direcciones + ciudad + provincia | `address_sk` |
| `dim_store` | tiendas fÃ­sicas + direcciÃ³n y provincia | `store_sk` |

---

### ğŸ“Œ Tablas de Hechos

| Tabla | Grano | MÃ©tricas |
|-------|-------|----------|
| `fact_sales_order` | una fila por orden | subtotal, impuestos, total |
| `fact_sales_order_item` | una fila por producto vendido | cantidad, precio unitario, descuentos, total lÃ­nea |
| `fact_payment` | transacciones de pago | monto, mÃ©todo, estado |
| `fact_shipment` | envÃ­os procesados | carrier, fechas, estado |
| `fact_web_session` | sesiones web | fuente, dispositivo, duraciÃ³n |
| `fact_nps_response` | respuestas NPS | puntaje, comentario, canal |

---

## âœ… EjecuciÃ³n

### 1ï¸âƒ£ Instalar dependencias
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Ejecutar el pipeline completo
```
python main.py
```

Al finalizar, la consola mostrarÃ¡:

âœ… DW (STAR SCHEMA) generado: dimensiones y hechos exportados a warehouse/


Las carpetas warehouse/dim/ y warehouse/fact/ contendrÃ¡n todos los CSV transformados.

### ğŸ“Š Dashboard (Looker Studio o Power BI)

El modelo resultante permite analizar:

-Ventas totales ($)

-Usuarios activos

-Ticket promedio

-Ventas por provincia y canal

-Ranking mensual de productos

-DistribuciÃ³n y tendencia de NPS

-MÃ©tricas logÃ­sticas (envÃ­os y pagos)

### âœ… Entregables de este repositorio

âœ” Pipeline ETL completo (extract â†’ transform â†’ load)
âœ” Modelo dimensional segÃºn Kimball (STAR SCHEMA)
âœ” Tablas CSV finales listas para BI
âœ” CÃ³digo modular, limpio y reproducible
âœ” EjecuciÃ³n desde consola mediante main.py

### ğŸ§¾ AutorÃ­a

Proyecto desarrollado por Paz Sevilla, Licenciatura en Ciencia de Datos â€“ Universidad Austral (2025).
Los archivos raw provienen del repositorio acadÃ©mico provisto por la cÃ¡tedra y fueron utilizados Ãºnicamente con fines educativos.
